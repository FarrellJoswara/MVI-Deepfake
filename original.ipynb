{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wave\n",
    "# Set paths\n",
    "DATA_DIR = '/Users/E6EKI5G/Desktop/ASVspoof'  # Replace with your dataset path\n",
    "REAL_DIR = os.path.join(DATA_DIR, 'real')\n",
    "FAKE_DIR = os.path.join(DATA_DIR, 'fake')\n",
    "# Parameters\n",
    "SR = 16000\n",
    "N_MFCC = 40\n",
    "MAX_LENGTH = 400  # Adjust based on your dataset\n",
    "# Helper function to check if a file is a valid WAV file\n",
    "def is_valid_wav(file_path):\n",
    "   try:\n",
    "       with wave.open(file_path, 'r') as file:\n",
    "           return True\n",
    "   except wave.Error as e:\n",
    "       print(f\"File {file_path} is not a valid WAV file: {e}\")\n",
    "       return False\n",
    "# Helper function to load and preprocess audio files\n",
    "def load_audio(file_path, sr=SR):\n",
    "   try:\n",
    "       if not is_valid_wav(file_path):\n",
    "           raise ValueError(f\"File {file_path} is not a valid WAV file\")\n",
    "       audio, sr = librosa.load(file_path, sr=sr)\n",
    "       return audio\n",
    "   except (EOFError, ValueError, RuntimeError) as e:\n",
    "       print(f\"Error loading {file_path}: {e}\")\n",
    "       return None\n",
    "# Helper function to extract MFCC features\n",
    "def extract_features(file_path):\n",
    "   audio = load_audio(file_path)\n",
    "   if audio is None:\n",
    "       return None\n",
    "   mfccs = librosa.feature.mfcc(y=audio, sr=SR, n_mfcc=N_MFCC)\n",
    "   if mfccs.shape[1] > MAX_LENGTH:\n",
    "       mfccs = mfccs[:, :MAX_LENGTH]\n",
    "   else:\n",
    "       mfccs = np.pad(mfccs, ((0, 0), (0, MAX_LENGTH - mfccs.shape[1])), mode='constant')\n",
    "   return mfccs\n",
    "# Load dataset and extract features\n",
    "def load_dataset(real_dir, fake_dir):\n",
    "   X = []\n",
    "   y = []\n",
    "   real_files = glob.glob(os.path.join(real_dir, '*.wav'))\n",
    "   fake_files = glob.glob(os.path.join(fake_dir, '*.wav'))\n",
    "   for file in real_files:\n",
    "       features = extract_features(file)\n",
    "       if features is not None:\n",
    "           X.append(features)\n",
    "           y.append(0)  # 0 for real\n",
    "   for file in fake_files:\n",
    "       features = extract_features(file)\n",
    "       if features is not None:\n",
    "           X.append(features)\n",
    "           y.append(1)  # 1 for fake\n",
    "   X = np.array(X)\n",
    "   y = np.array(y)\n",
    "   return X, y\n",
    "# Prepare data\n",
    "X, y = load_dataset(REAL_DIR, FAKE_DIR)\n",
    "X = X[..., np.newaxis]  # Add channel dimension\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential([\n",
    "   layers.Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]),\n",
    "   layers.MaxPooling2D((2, 2)),\n",
    "   layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "   layers.MaxPooling2D((2, 2)),\n",
    "   layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "   layers.MaxPooling2D((2, 2)),\n",
    "   layers.Flatten(),\n",
    "   layers.Dense(128, activation='relu'),\n",
    "   layers.Dropout(0.5),\n",
    "   layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
